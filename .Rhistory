source("test.R")
source("test.R")
cr <- corr("specdata", 150)
head(cr)
ls()
source("corr.R")
ls()
cr <- corr("specdata", 150)
head(cr)
summary(cr)
cr <- corr("specdata", 400)
head(cr)
summary(cr)
cr <- corr("specdata", 5000)
summary(cr)
length(cr)
cr <- corr("specdata")
summary(cr)
length(cr)
submit()
submit()
submit()
source("test.R")
z <- 10
f(3)
getwd()
ls()
rm(list = ls())
ls()
list.files
getwd()
list.files()
outcome <- read.csv("outcome-of-care-measures.csv", colClasses = "character")
outcome <- read.csv("outcome-of-care-measures.csv", colClasses = "character")
head(outcome)
ncol(outcome)
nrow(outcome)
names(outcome)
outcome[,11] <- as.numeric(outcome[,11])
hist(outcome[,11])
## Return hospital name in that state with lowest 30-day death
source("best.R")
ls()
best("MA","test")
best("ss","test")
best("ss","heart attack")
best("MA","heart attack")
data <- read.csv("outcome-of-care-measures.csv", stringsAsFactors=FALSE)
test <- data[data$State==state,]
test <- data[data$State=='MA',]
str(test)
source("best.R")
best("MA","heart attack")
best("TX","heart attack")
best("TX","heart failure")
best("MD","heart attack")
best("MD","pneumonia")
best("BB","pneumonia")
best("NY","hert attack")
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript3.R")
submit()
2
submit()
submit()
source("rankhospital.R")
rankhospital("TX", "heart failure", 4)
rankhospital("MD", "heart attack", "worst")
rankhospital("MN", "heart attack", 5000)
rankhospital("BB", "heart attack", "best")
rankhospital("MA", "hert attack", "best")
submit()
submit()
submit()
submit()
source("rankall.R")
head(rankall("heart attack", 20), 10)
head(rankall("heart attack", 20), 10)
source("rankall.R")
head(rankall("heart attack", 20), 10)
source("rankall.R")
head(rankall("heart attack", 20), 10)
tail(rankall("pneumonia", "worst"), 3)
tail(rankall("heart failure"), 10)
submit()
submit()
submit()
set.seed(1)
rpois(5, 2)
require(gdata)
gov <- read.xslx("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx")
gov <- read.xls("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx")
rm(list = ls())
ls()
clear()
ls()
getwd()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx","gov_data.xslx",method="curl")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx","gov_data.xlsx",method="curl")
install.packages("RCurl")
library(RCurl)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx","gov_data.xlsx",method="curl")
getURL("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx")
download.file(url='https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx',destfile='localfile.xlsx', method='curl')
download.file(url='https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx',destfile='localfile.xlsx', method='auto')
download.file(url="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx",destfile="gov-data.xlsx", method="auto")
getwd()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx",destfile="gov-data.xlsx", method="auto")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx",destfile="gov-data.xlsx", method="curl")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx",destfile="gov-data.xlsx")
library(xlsx)
install.packages("xlsx")
library(xlsx)
df <- read.xlsx("gov-data.xlsx",sheetIndex=1,header=TRUE)
ls()
getwd()
library(xslx)
install.packages("xslx")
install.packages("xslx")
install.packages("xlsx")
library(xlsx)
Sys.getenv('JAVA')
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_45')
library(xlsx)
library(xlsx)
install()
install.packages("xlsx")
library(xlsx)
df <- read.xlsx("gov-data.xlsx")
install.packages("xlconnect")
install.packages("XLConnect")
library(XLConnect)
library("XLConnect", lib.loc="~/R/win-library/3.2")
install.packages("rJava")
library("XLConnect", lib.loc="~/R/win-library/3.2")
library("XLConnect")
library("rJava")
library(rJava)
getwd()
library(xlsx)
getwd()
list.files()
ls()
load(xlsx)
library(xlsx)
install.packages("xlsx")
library(xlsx)
install.packages("rJava")
library(xlsx)
library(xlsx)
df <- read.xlsx("gov-data.xlsx", sheetIndex = 1, header = TRUE)
rowIndex <- 18:23
colIndex <- 7:15
dat <- read.xlsx(file="gov-data.xlsx", sheetIndex=1, colIndex=colIndex, rowIndex=rowIndex, header=TRUE)
library(xlsx)
dat <- read.xlsx(file="gov-data.xlsx", sheetIndex=1, colIndex=colIndex, rowIndex=rowIndex, header=TRUE)
head(dat)
sum(dat$Zip*dat$Ext, na.rm=T)
install.packages("xml")
install.packages("XML")
library(XML)
install.packages("rJava")
install.packages("xlsx")
library(rJava)
library(xlsx)
install.packages("XML")
library(XML)
file <- "http://d396qusza40orc.cloudfront.net/getdata/data/restaurants.xml"
my.doc <- xmlTreeParse(file=file,useInternal=TRUE)
root.Node <- xmlRoot(my.doc)
xmlName(root.Node)
zipcode <- xpathSApply(root.Node, "//zipcode", xmlValue)
length(zipcode[zipcode==21231])
install.packages("data.table")
library(data.table)
install.packages("httr")
library(httr)
require(httpuv)
install.packages("httpuv")
install.packages("jsonlite")
require(httpuv)
require(jsonlite)
oauth_endpoints("github")
myapp <- oauth_app("quiz2", "33d87e22d0e91be04ab1", secret="db8e2a11ed1d83522bbf6d8cccfff68d66cf5e55")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
stop_for_status(req)
output <- content(req)
list(output[[4]]$name, output[[4]]$created_at)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
content(req)
BROWSE("https://api.github.com/users/jtleek/repos",authenticate("Access Token","x-oauth-basic","basic"))
BROWSE("https://api.github.com/users/jtleek/repos",authenticate("Access Token","x-oauth-basic","basic"))
connection <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode <- readLines(connection)
close(connection)
c(nchar(htmlCode[10]), nchar(htmlCode[20]), nchar(htmlCode[30]), nchar(htmlCode[100]))
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
lines <- readLines(url, n=10)
w <- c(1, 9, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3)
colNames <- c("filler", "week", "filler", "sstNino12", "filler", "sstaNino12", "filler", "sstNino3", "filler", "sstaNino3", "filler", "sstNino34", "filler", "sstaNino34", "filler", "sstNino4", "filler", "sstaNino4")
d <- read.fwf(url, w, header=FALSE, skip=4, col.names=colNames)
d <- d[, grep("^[^filler]", names(d))]
sum(d[, 4])
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
library(data.table)
library(downloader)
getwd()
download(url, dest="data.csv", mode="wb")
data - read.csv("data.csv", header=TRUE)
data = read.csv("data.csv", header=TRUE)
View(data)
names(data)[123]
strsplit(names(data)[123], "wgtp")
names(data)[123]
data = read.csv("data.csv", header=TRUE)
names(data)
strsplit(names(data), "wgtp")
names(data)
strsplit(names(data), "wgtp")
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download(url, dest="data2.csv", mode="wb")
data2 = read.csv("data2.csv", header=TRUE)
View(data2)
data3 <- data2[5:194]
data3 <- data2[5:194,]
View(data3)
clean_data <- gsub(",", "", data3[, 5])
numData <- as.numeric(clean_data)
mean(numData)
countryNames <- data3[,4]
regexec("^United", countryNames)
grep("^United",countryNames)
grep("*United",countryNames)
grep("United$",countryNames)
url1 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
url2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download(url1, dest="gdp.csv", mode="wb")
download(url2, dest="edu.csv", mode="wb")
gdp = read.csv("gdp.csv", header=TRUE)
edu = read.csv("edu.csv", header=TRUE)
View(gdp)
View(edu)
newGdpData <- gdp[5:194, c(1, 2, 4, 5)]
colnames(newGdpData) <- c("CountryCode", "Ranking", "Economy", "GDP"
View(newGdpData)
colnames(newGdpData) <- c("CountryCode", "Ranking", "Economy", "GDP")
View(newGdpData)
rownames(newGdpData) <- NULL
View(newGdpData)
names(edu)
mergedData <- merge(newGdpData, edu, by.x="CountryCode", by.y="CountryCode", all=TRUE)
View(mergedData)
head(mergedData)
names(mergedData) <- tolower(names(mergedData))
a <- as.character(mergedData[,13])
length(grep("Fiscal year end: June", a))
library(quantmod)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
str(sampleTimes)
length(sampleTimes)
bool1 <- year(sampleTimes) == 2012
length(sampleTimes[bool1])
bool2 <- weekdays(sampleTimes)=="Monday"
length(sampleTimes[bool1 & bool2])
install.packages("ggplot2")
library(ggplot2)
str(mpg)
qplot(displ, hwy, data=mpg)
qplot(displ, hwy, data=mpg, color=drv)
qplot(displ, hwy, data=mpg, geom=c("point","smooth"))
qplot(hwy, data=mpg, fill=drv)
qplot(displ, hwy, data=mpg, facets=.~drv)
str(maacs)
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(datasets)
data(airquality)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library(ggplot2)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library(lattice)
# Reproducible Research - Course Project 1
Jack Welch
# Reproducible Research - Course Project 1
Jack Welch
October, 2016
## Introduction
This is our first project within the **Reproducible Research** course in John Hopkins University Data Science Specialization offered on Coursera. This project will introduce us to activity or fitment data collected from monitoring devices available from organizations such as FitBit, Nike, Fuelband, or Jawbone Up.  This assignment will specifically introduce us to Literate Statistical Programming whereby we can create a written report and include the analytical techniques within the body of the same document.  We will work with KnitR and we will use the R Markdown language for creating written reports with the support of R programming scripts that can produce dynamic analysis and visualization within the written report.
# Reproducible Research - Course Project 1
Jack Welch
---
# Reproducible Research - Course Project 1
Jack Welch
install.packages("tidyr")
library("swirl")
swirl()
swirl()
install_course("Statistical_Inference")
library("swirl")
install_course("Statistical_Inference")
library(swirl)
install_course("Statistical_Inference")
install.packages("swirl")
install.packages("swirl")
install_course("Statistical_Inference")
library(swirl)
install_course("Statistical_Inference")
swirl()
dice_sqr
ex2_fair <- sum(dice_sqr*dice_fair)
ex2_fair-3.5^2
sum(dice_sqr*dice_high)-3.5^2
sum(dice_sqr*dice_high)-edh^2
sd(apply(matrix(rnorm(10000),1000),1,mean))
1/sqrt(10)
1/sqrt(120)
sd(apply(matrix(runif(10000),1000),1,mean))
2/sqrt(10)
sd(apply(matrix(rpois(10000,4),1000),1,mean))
1/(2*sqrt(10))
sd(apply(matrix(sample(0:1,10000,TRUE),1000),1,mean))
.8*3
x=3,4,5
x=[3,4,5]
x=3
choose(5,3)*(.8)^3*(.2)^(5-3)+choose(5,4)*(.8)^4*(.2)^(5-4)+choose(5,5)*(.8)^5*(.2)^(5-5)
pbinom(2,5,.8,lower.tail=false)
pbinom(2,5,.8,lower.tail = false)
pbinom(2,5,.8)
pbinom(2,size=5,prob=.8,lower.tail=FALSE)
qnorm(.1)
0
qnorm(97.5, mean=3, sd=2)
qnorm(.975, mean=3, sd=2)
3+1.96*2
pnorm(1200, mean=1020, sd=50, lower.tail=FALSE)
(1200-1020)/50
pnorm((1200-1020)/50,lower.tail=FALSE)
qnorm(.75, mean=1020, sd=50)
pnorm(qnorm(.53))
.53
ppois(3, lambda=2.5)
ppois(3, lambda=2.5*4)
pbino(5,1000,.1)
pbinom(5,1000,.1)
pbinom(5,1000,.01)
ppois(5,10000*.01)
ppois(5,1000*.01)
exit
quit
library("swirl")
swirl()
coinPlot(10)
coinPlot(10000)
swirl()
upgrade.packages
upgrade.packages()
update.packages()
swirl()
install.packages("ymax")
updateR()
install.packages("installr")
updateR()
require("installR")
updateR()
install.packages("curl")
install.packages("curl")
install.packages(c("curl", "ggplot2", "Rcpp", "XLConnect", "XLConnectJars", "XML"))
install.packages("curl")
library("swirl")
swirl()
install.packages("swirl")
library("swirl")
install.packages("stringi")
library("swirl")
swirl()
install.packages(p, quiet = TRUE)
install.packages("ggplot2")
swirl()
library("swirl")
swirl()
install.packages(p, quiet = TRUE)
library("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("swirl")
install.packages("swirl")
install.packages("ggplot2")
library("swirl")
swirl()
coinPlot(10)
coinPlot(10000)
qnorm(.95)
p'+/- qnorm(.975)*sqrt(p'(1-p')/100)
.6 + c(-1,1)*qnorm(.975)*sqrt(.6*.4/100)
binom.test(60,100)$conf.int
mywald(.2)
ACCompar(20)
lamb <- 5/94.32
lamb +c(-1,1)*qnorm(.975)*sqrt(lamb/94.32)
poisson.test(5,94.32)$conf
library("swirl")
swirl()
myplot(2)
myplot(20)
myplot2(2)
qt(.975,2)
myplot2(20)
sleep
range(g1)
range(g2)
difference <- g2 - g1
mean(difference)
s <- sd(difference)
mn + c(-1,1)*qt(.975,9)*s/sqrt(10)
t.test(difference)$conf.int
sp <- 7*15.34^2 + 20*18.23^2
ns <- 8+21-2
sp <- sqrt(sp/ns)
132.86-127.44+c(-1,1)*qt(.975,ns)*sp*sqrt(1/8+1/21)
sp <- sqrt((9*var(g1)+9*var(g2))/18)
md + c(-1,1)*qt(.975,18)*sp*sqrt(1/5)
t.test(g2,g1,paired=FALSE,var.equal=TRUE)$conf
t.test(g2,g1,paired=TRUE,var.equal=TRUE)$conf
t.test(g2,g1,paired=TRUE)$conf
num <- (15.34^2/8 + 18.23^2/21)^2
den <- 15.34^4/8^2/7 + 18.23^4/21^2/20
mydf <- num/den
132.86-127.44 +c(-1,1)*qt(.975,mydf)*sqrt(15.34^2/8 + 18.23^2/21)
library("swirl")
swirl()
10/sqrt(100)
2
(32-30)/(10/4)
15
qt(.95,15)
dim(fs)
t.test(fs$sheight-fs$fheight)
11.7885 * sd(fs$sheight-fs$fheight)/sqrt(1078)
mybin
8
library("swirl")
swirl()
swirl()
library("swirl")
swirl()
pt(2.5,15,lower.tail=FALSE)
qnorm(.95)
qnorm(.99)
pnorm(2)
pnorm(2,lower.tail=FALSE)
mybin
pbinom(6,size=8,prob=.5,lower.tail=FALSE)
pbinom(7,size=8,prob-0.5,lower.tail=TRUE)
pbinom(7,size=8,prob=0.5,lower.tail=TRUE)
ppois(9,5,lower.tail=FALSE)
library("swirl")
swirl()
head(pValues)
sum(pValues<0.05)
sum(p.adjust(pValues,method="bonferroni") < 0.05)
sum(p.adjust(pValues,method="BH") < 0.05)
tail(trueStatus)
table(pValues2 < 0.05, trueStatus)
24/500
table(p.adjust(pValues2,method="bonferroni") < 0.05, trueStatus)
table(p.adjust(pValues2,method="BH") < 0.05, trueStatus)
1
sum(1:6)/6
g2
print(g2)
head(sh)
nh
median(resampledMedians)
median(sh)
sam <- sample(fh,nh*B,replace=TRUE)
resam <- matrix(sam,B,nh)
meds <- apply(resam,1,median)
median(meds)-median(fh)
sd(meds)
sd(resampledMedians)
quantile(resampledMedians,c(.025,.975))
quantile(meds,c(.025,.975))
dim(InsectSprays)
names(InsectSprays)
range(Bdata$count)
range(Cdata$count)
BCcounts
group
testStat
obs <- testStat(BCcounts,group)
obs
mean(Bdata$count)-mean(Cdata$count)
sample(group)
perms <- sapply(1 : 10000, function(i) testStat(BCcounts, sample(group)))
mean(perms>obs)
testStat(DEcounts,group)
perms <- sapply(1 : 10000, function(i) testStat(DEcounts, sample(group)))
setwd("C:/Users/End User/statistical-inference")
install.packages("knitr")
library("knitr")
setwd("C:/Users/End User/NCDC-Storm-Events-Database")
install.packages("rmarkdown")
setwd("C:/Users/End User/statistical-inference")
